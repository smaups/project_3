{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olympic Data\n",
    "We pared down a Kaggle data set to the Summer data. We included only the data necessary for our searching.\n",
    "## The Dataset\n",
    "The following information about each participant in each event are included within the CSV:\n",
    "\n",
    "* ID: unique identifier for each participant\n",
    "* Name: each participant's name\n",
    "* Sex: M for male, F for female\n",
    "* Age: in years (11 to 71)\n",
    "* Height: in cm\n",
    "* Weight: in kilograms\n",
    "* Team: Group the participant is competing with\n",
    "* NOC: Three letter country abbreviation\n",
    "* Year: Year of Olympic event (1896-2016)\n",
    "* Sport: Category of competetion\n",
    "* Medal: NA(no medal), Bronze, Silver, Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Medal_Type</th>\n",
       "      <th>Medals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>180</td>\n",
       "      <td>80.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>60.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012</td>\n",
       "      <td>Judo</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Jyri Tapani Aalto</td>\n",
       "      <td>M</td>\n",
       "      <td>31</td>\n",
       "      <td>172</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>FIN</td>\n",
       "      <td>2000</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>Minna Maarit Aalto</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>159</td>\n",
       "      <td>55.5</td>\n",
       "      <td>Finland</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1996</td>\n",
       "      <td>Sailing</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>Minna Maarit Aalto</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>159</td>\n",
       "      <td>55.5</td>\n",
       "      <td>Finland</td>\n",
       "      <td>FIN</td>\n",
       "      <td>2000</td>\n",
       "      <td>Sailing</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>No Medal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                Name Sex  Age  Height  Weight     Team  NOC  Year  \\\n",
       "0   1           A Dijiang   M   24     180    80.0    China  CHN  1992   \n",
       "1   2            A Lamusi   M   23     170    60.0    China  CHN  2012   \n",
       "2  12   Jyri Tapani Aalto   M   31     172    70.0  Finland  FIN  2000   \n",
       "3  13  Minna Maarit Aalto   F   30     159    55.5  Finland  FIN  1996   \n",
       "4  13  Minna Maarit Aalto   F   34     159    55.5  Finland  FIN  2000   \n",
       "\n",
       "        Sport Medal_Type     Medals  \n",
       "0  Basketball    No Medal  No Medal  \n",
       "1        Judo    No Medal  No Medal  \n",
       "2   Badminton    No Medal  No Medal  \n",
       "3     Sailing    No Medal  No Medal  \n",
       "4     Sailing    No Medal  No Medal  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olympics_unfiltered = pd.read_csv('Summer_Olympics.csv')\n",
    "olympics_unfiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_filtered = olympics_unfiltered[olympics_unfiltered[\"Year\"] > 1913].reset_index()\n",
    "olympics_filtered = olympics_unfiltered[olympics_unfiltered[\"Sport\"] != \"Art Competitions\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Medal_Type</th>\n",
       "      <th>NOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>180</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>CHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>Judo</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>CHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>31</td>\n",
       "      <td>172</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>Badminton</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>159</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1996</td>\n",
       "      <td>Sailing</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>159</td>\n",
       "      <td>55.5</td>\n",
       "      <td>2000</td>\n",
       "      <td>Sailing</td>\n",
       "      <td>No Medal</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Age  Height  Weight  Year       Sport Medal_Type   NOC\n",
       "0   M   24     180    80.0  1992  Basketball    No Medal  CHN\n",
       "1   M   23     170    60.0  2012        Judo    No Medal  CHN\n",
       "2   M   31     172    70.0  2000   Badminton    No Medal  FIN\n",
       "3   F   30     159    55.5  1996     Sailing    No Medal  FIN\n",
       "4   F   34     159    55.5  2000     Sailing    No Medal  FIN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_event_df = olympics_filtered[[\"Sex\", \"Age\", \"Height\", \"Weight\", \"Year\", \"Sport\", \"Medal_Type \", \"NOC\"]]\n",
    "physical_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Pre-Processing Medal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166677, 7) (166677,)\n"
     ]
    }
   ],
   "source": [
    "X = physical_event_df.drop(\"Medal_Type \", axis=1)\n",
    "y = physical_event_df[\"Medal_Type \"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166677, 274)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X.head()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from sklearn.preprocessing import *\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125007"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## y_train Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y = label_encoder.transform(y_train)\n",
    "len(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125007"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_y = to_categorical(encoded_y)\n",
    "len(one_hot_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41670"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## y_test Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_test)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "len(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41670"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_y_test = to_categorical(encoded_y_test)\n",
    "len(one_hot_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "#Scale the Dataset\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Model\n",
    "model = tensorflow.keras.Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=274))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               27500     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 32,754\n",
      "Trainable params: 32,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125007/125007 - 5s - loss: 0.5095 - acc: 0.8519\n",
      "Epoch 2/10\n",
      "125007/125007 - 5s - loss: 0.4719 - acc: 0.8560\n",
      "Epoch 3/10\n",
      "125007/125007 - 5s - loss: 0.4582 - acc: 0.8572\n",
      "Epoch 4/10\n",
      "125007/125007 - 5s - loss: 0.4492 - acc: 0.8581\n",
      "Epoch 5/10\n",
      "125007/125007 - 5s - loss: 0.4430 - acc: 0.8588\n",
      "Epoch 6/10\n",
      "125007/125007 - 5s - loss: 0.4381 - acc: 0.8596\n",
      "Epoch 7/10\n",
      "125007/125007 - 5s - loss: 0.4336 - acc: 0.8600\n",
      "Epoch 8/10\n",
      "125007/125007 - 5s - loss: 0.4294 - acc: 0.8609\n",
      "Epoch 9/10\n",
      "125007/125007 - 5s - loss: 0.4265 - acc: 0.8611\n",
      "Epoch 10/10\n",
      "125007/125007 - 5s - loss: 0.4234 - acc: 0.8616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb313c5320>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    one_hot_y,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "41670/41670 - 1s - loss: 0.4468 - acc: 0.8613\n",
      "Normal Neural Network - Loss: 0.4467886146604085, Accuracy: 0.8613150715827942\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\" \")\n",
    "print(\" \")\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, one_hot_y_test, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d7128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d7128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d7128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d7128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d73c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d73c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d73c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d73c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d79e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d79e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d79e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0xb322d79e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n",
    "                        initial_sparsity=0, final_sparsity=.9,\n",
    "                        begin_step=1000, end_step=5000)\n",
    "\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule=pruning_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_dense_3  (None, 100)               54902     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_4  (None, 50)                10052     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_5  (None, 2)                 204       \n",
      "=================================================================\n",
      "Total params: 65,158\n",
      "Trainable params: 32,652\n",
      "Non-trainable params: 32,506\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125007 samples, validate on 41670 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [Prune() wrapper requires the UpdatePruningStep callback to be provided during training. Please add it as a callback to your model.fit call.] [Condition x >= y did not hold element-wise:x (prune_low_magnitude_dense_3_2/cond/assert_greater_equal/ReadVariableOp:0) = ] [-1] [y (prune_low_magnitude_dense_3_2/cond/assert_greater_equal/y:0) = ] [0]\n\t [[{{node prune_low_magnitude_dense_3_2/cond/assert_greater_equal/Assert/Assert}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-b99ae61423d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/anaconda3/envs/PythonData/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [Prune() wrapper requires the UpdatePruningStep callback to be provided during training. Please add it as a callback to your model.fit call.] [Condition x >= y did not hold element-wise:x (prune_low_magnitude_dense_3_2/cond/assert_greater_equal/ReadVariableOp:0) = ] [-1] [y (prune_low_magnitude_dense_3_2/cond/assert_greater_equal/y:0) = ] [0]\n\t [[{{node prune_low_magnitude_dense_3_2/cond/assert_greater_equal/Assert/Assert}}]]"
     ]
    }
   ],
   "source": [
    "model_for_pruning.fit(\n",
    "    X_train_scaled,\n",
    "    one_hot_y,\n",
    "    batch_size=1000,\n",
    "    epochs=2,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test_scaled, one_hot_y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
